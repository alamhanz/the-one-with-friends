{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"20200803_training_bert_TPU.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"94bf3e937a314980906c7b88a215f957":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0478a5c772ba4fb49e6cadcc944f1d76","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0b12b70674a5450d88fb014557022d96","IPY_MODEL_a491c0757137482b844e42c4c654230a"]}},"0478a5c772ba4fb49e6cadcc944f1d76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b12b70674a5450d88fb014557022d96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a96ab4a7df504e92a1f75eef1210eb2f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51a16dd60d42490599f1710064298362"}},"a491c0757137482b844e42c4c654230a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_104054252d8d4070b2a349d5fd96daf8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.40MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4eec5bd6bfa4c879c342633de0c9063"}},"a96ab4a7df504e92a1f75eef1210eb2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51a16dd60d42490599f1710064298362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"104054252d8d4070b2a349d5fd96daf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4eec5bd6bfa4c879c342633de0c9063":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"g5_fZUzo02xP","colab_type":"text"},"source":["# Friends Classification Text\n","\n","This is classification of dialogue in FRIENDS TV Series.\n","\n","<!-- https://stackoverflow.com/questions/61000500/tensorflow-keras-bert-multiclass-text-classification-accuracy -->"]},{"cell_type":"code","metadata":{"id":"03Lpsmju02xR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596546434909,"user_tz":-420,"elapsed":36080,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"8f88e730-adf7-481d-ca78-85d5625321b4"},"source":["import pandas as pd\n","import re\n","import numpy as np\n","import time\n","\n","import os\n","import pprint\n","import tensorflow as tf\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nplks9aMi_aH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546434919,"user_tz":-420,"elapsed":33443,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# help(drive.mount)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6n6vof_02xV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546439781,"user_tz":-420,"elapsed":3319,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["PATH_DATA = '../../data/'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvelJ79e02xY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546440448,"user_tz":-420,"elapsed":2536,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7g_TiNQM1LvY","colab_type":"text"},"source":["## Checking Machine"]},{"cell_type":"code","metadata":{"id":"WWQMw6cQ1NtR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596546441442,"user_tz":-420,"elapsed":1898,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"6ffcf0e0-df4c-436e-f2e3-0ee9e05719b0"},"source":["if 'COLAB_TPU_ADDR' not in os.environ:\n","  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n","else:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  print ('TPU address is', tpu_address)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TPU address is grpc://10.62.78.122:8470\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uQwZJZB61Nwm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546442437,"user_tz":-420,"elapsed":1851,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lMeZ84P02xb","colab_type":"text"},"source":["## Importing Data"]},{"cell_type":"code","metadata":{"id":"3Nfyykbz1wZv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596546443499,"user_tz":-420,"elapsed":1724,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"45e5a072-0cdb-461e-802a-c6787a8c1b42"},"source":["%cd gdrive/My Drive/Repository/the-one-with-friends/notebooks/bert_model"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Repository/the-one-with-friends/notebooks/bert_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZCCTJo2o1dDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596546444565,"user_tz":-420,"elapsed":1238,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"f06ec35b-43a4-474d-e09c-55d704605380"},"source":["os.listdir()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.ipynb_checkpoints',\n"," '20200803_Data_Preparation.ipynb',\n"," '20200803_training_bert.ipynb',\n"," 'bert_learn.ipynb',\n"," '20200803_training_bert_TPU.ipynb']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"dHeMuViP02xb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546445695,"user_tz":-420,"elapsed":1712,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["df_dlg_seen = pd.read_csv('../../data/friends_seen_season.csv')\n","df_dlg_unseen = pd.read_csv('../../data/friends_unseen_season.csv')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_VRmC1602xe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546446287,"user_tz":-420,"elapsed":747,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["data_train = df_dlg_seen[df_dlg_seen.is_train == True][['text','label']]\n","data_test = df_dlg_seen[df_dlg_seen.is_train == False][['text','label']]\n","data_unseen = df_dlg_unseen[['text','label']]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tt421RVa02xh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596546446759,"user_tz":-420,"elapsed":758,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"e4ca203a-0c9e-4c4c-f72a-6cbedd3d0dd2"},"source":["data_train.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(35123, 2)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"LnHpAS_J02xk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596546448627,"user_tz":-420,"elapsed":1271,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"014e56d0-0668-4ae9-875f-6203c440a139"},"source":["data_test.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11708, 2)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"u1kNu3H602xo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596546449095,"user_tz":-420,"elapsed":1223,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"253bdfb8-ac3e-403b-b6ad-96fda5751884"},"source":["data_unseen.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11207, 2)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"L1J6bjri02xr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546449807,"user_tz":-420,"elapsed":1466,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5KQGGRST02xu","colab_type":"text"},"source":["## Tokenizer"]},{"cell_type":"code","metadata":{"id":"SBGtoVam2ION","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546475562,"user_tz":-420,"elapsed":857,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# !pip install transformers"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcAEmNSn02xu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546478359,"user_tz":-420,"elapsed":967,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# from transformers import BertTokenizer\n","\n","# bert_token = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","# MAX_LEN = 25\n","# NUMB_CLASS = 7\n","\n","# # Tokenizer use bert\n","# def text_to_feature(x,tokenizer = bert_token):\n","#     text_token = tokenizer.encode_plus(\n","#                     x,                      \n","#                     add_special_tokens = True, # add [CLS], [SEP]\n","#                     max_length = MAX_LEN, # max length of the text that can go to BERT\n","#                     pad_to_max_length = True, # add [PAD] tokens\n","#                     return_attention_mask = True,\n","#                     truncation=True,# add attention mask to not focus on pad tokens\n","#                   )\n","#     return text_token\n","\n","# # map to the expected input to TFBertForSequenceClassification, see here \n","# def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n","#     return {\n","#       \"input_ids\": input_ids,\n","#       \"token_type_ids\": token_type_ids,\n","#       \"attention_mask\": attention_masks,\n","#     }, label\n","\n","\n","# def label_encode(i, numb_cls):\n","#     X = np.zeros(numb_cls)\n","#     X[i] = 1\n","#     return list(X)\n","\n","# def encode_dataset(ds, limit=-1):\n","#     # prepare list, so that we can build up final TensorFlow dataset from slices.\n","#     input_ids_list = []\n","#     token_type_ids_list = []\n","#     attention_mask_list = []\n","#     label_list = []\n","#     if (limit > 0):\n","#         ds = ds.head(limit)\n","    \n","#     for text, label in ds.values:\n","#         bert_input = text_to_feature(text)\n","#         input_ids_list.append(bert_input['input_ids'])\n","#         token_type_ids_list.append(bert_input['token_type_ids'])\n","#         attention_mask_list.append(bert_input['attention_mask'])\n","        \n","#     return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_CcwBtOmxzy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["94bf3e937a314980906c7b88a215f957","0478a5c772ba4fb49e6cadcc944f1d76","0b12b70674a5450d88fb014557022d96","a491c0757137482b844e42c4c654230a","a96ab4a7df504e92a1f75eef1210eb2f","51a16dd60d42490599f1710064298362","104054252d8d4070b2a349d5fd96daf8","a4eec5bd6bfa4c879c342633de0c9063"]},"executionInfo":{"status":"ok","timestamp":1596546483826,"user_tz":-420,"elapsed":4939,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"3382a451-c476-498d-bf1e-1363efdc6fb8"},"source":["from transformers import BertTokenizer\n","\n","bert_token = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Tokenizer use bert\n","def text_to_feature(x,max_seq,tokenizer = bert_token):\n","    text_token = tokenizer.encode_plus(\n","                    x,                      \n","                    add_special_tokens = True, # add [CLS], [SEP]\n","                    max_length = max_seq, # max length of the text that can go to BERT\n","                    pad_to_max_length = True, # add [PAD] tokens\n","                    return_attention_mask = True,\n","                    truncation=True,# add attention mask to not focus on pad tokens\n","\n","                    return_tensors='tf',\n","                  )\n","    return text_token\n","\n","def label_encode(i, numb_cls):\n","    X = np.zeros(numb_cls)\n","    X[i] = 1\n","    return list(X)\n","\n","def encode_dataset(ds, max_seq_len, limit=-1):\n","    # prepare list, so that we can build up final TensorFlow dataset from slices.\n","    input_ids_list = []\n","    token_type_ids_list = []\n","    attention_mask_list = []\n","    label_list = []\n","    if (limit > 0):\n","        ds = ds.head(limit)\n","    \n","    for text, label in ds.values:\n","        bert_input = text_to_feature(text,max_seq = max_seq_len)\n","        input_ids_list.append(bert_input['input_ids'])\n","        token_type_ids_list.append(bert_input['token_type_ids'])\n","        attention_mask_list.append(bert_input['attention_mask'])\n","        label_list.append(label_encode(label, NUMB_CLASS))\n","\n","    input_ids = tf.convert_to_tensor(input_ids_list)\n","    attention_masks = tf.convert_to_tensor(attention_mask_list)\n","    token_type_ids = tf.convert_to_tensor(token_type_ids_list)\n","\n","    ids = tf.reshape(input_ids, (-1, max_seq_len))\n","    print(\"Input ids shape: \", ids.shape)\n","    masks = tf.reshape(attention_masks, (-1, max_seq_len))\n","    print(\"Input Masks shape: \", masks.shape)\n","    token_types = tf.reshape(token_type_ids, (-1, max_seq_len))\n","    print(\"Token type ids shape: \", token_types.shape)\n","\n","    ids=ids.numpy()\n","    masks = masks.numpy()\n","    token_types = token_types.numpy()\n","    y = np.array(label_list)\n","        \n","    return [ids, masks, token_types, y]\n"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94bf3e937a314980906c7b88a215f957","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y1vS0VkKmOZR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546483845,"user_tz":-420,"elapsed":1309,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# ALL_TEST = encode_dataset(data_test, MAX_LEN)\n","# ALL_TEST[:3],ALL_TEST[3].shape"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wougnTMpWxj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596546489853,"user_tz":-420,"elapsed":1708,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cYqyu2RK02x6","colab_type":"text"},"source":["## Training Model"]},{"cell_type":"code","metadata":{"id":"JbdOHXqA02x6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547354559,"user_tz":-420,"elapsed":1091,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["from transformers import TFBertForSequenceClassification\n","from keras import Model\n","from keras.layers import Dense, Dropout, Flatten, Input\n","from keras import regularizers"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQBszBZQ3Yzd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547356876,"user_tz":-420,"elapsed":1023,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# def create_model(L_RATE, NUMB_CLASS_TARGET):\n","#   model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUMB_CLASS_TARGET)\n","#   optimizer = tf.keras.optimizers.Adam(learning_rate=L_RATE, epsilon=1e-08)\n","\n","#   loss = tf.keras.losses.CategoricalCrossentropy()\n","#   metric = tf.keras.metrics.CategoricalCrossentropy('accuracy')\n","\n","#   model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","#   return model\n","\n","\n","def create_model(L_RATE,max_seq_len,NUMB_CLASS_TARGET):\n","  base_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', trainable=True, num_labels=NUMB_CLASS_TARGET)\n","\n","  input_ids_layer = Input(shape=(max_seq_len, ), dtype=np.int32)\n","  input_mask_layer = Input(shape=(max_seq_len, ), dtype=np.int32)\n","  input_token_type_layer = Input(shape=(max_seq_len,), dtype=np.int32)\n","\n","  bert_layer = base_model([input_ids_layer, input_mask_layer, input_token_type_layer])[0]\n","  flat_layer = Flatten()(bert_layer)\n","  dropout_1= Dropout(0.5)(flat_layer)\n","  dense_1 = Dense(3*NUMB_CLASS_TARGET, activation='relu', \n","                  bias_regularizer=regularizers.l2(0.05),\n","                  activity_regularizer=regularizers.l2(0.05))(dropout_1)\n","\n","  dropout_2= Dropout(0.5)(dense_1)\n","  dense_2 = Dense(3*NUMB_CLASS_TARGET, activation='relu',\n","                  bias_regularizer=regularizers.l2(0.03),\n","                  activity_regularizer=regularizers.l2(0.03))(dropout_2)\n","\n","  dense_output = Dense(NUMB_CLASS_TARGET, activation='softmax',\n","                  bias_regularizer=regularizers.l2(0.02))(dense_2)\n","\n","  model_ = Model(inputs=[input_ids_layer, input_mask_layer, input_token_type_layer], outputs=dense_output)\n","\n","  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=L_RATE,\n","    decay_steps=100000,\n","    decay_rate=0.9)\n","  \n","  optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-08)\n","  model_.compile(optimizer=optimizer,\n","              loss=['categorical_crossentropy'],\n","              metrics=['accuracy'])\n","  \n","  #loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","  #metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","  #model_.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","  return model_\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kw1ZtZxdmaKX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547358843,"user_tz":-420,"elapsed":1476,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# mm = create_model(LR, MAX_LEN , NUMB_CLASS)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZVc0jotHmiCm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547358847,"user_tz":-420,"elapsed":812,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHof8BHk7FJF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596547359436,"user_tz":-420,"elapsed":872,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"1e7d91ab-04d0-44fa-9bb6-a5ecb02ebebf"},"source":["print(tf.__version__)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SKvzYkhC7CHN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547360435,"user_tz":-420,"elapsed":1256,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"KA1k9kZc290S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":870},"executionInfo":{"status":"ok","timestamp":1596547418947,"user_tz":-420,"elapsed":57927,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"93a406aa-d6af-421f-b949-d971a9c66b7c"},"source":["# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n","LR = 1e-5\n","EPOCHS = 230\n","BATCH_SIZE = 250\n","MAX_LEN = 15\n","NUMB_CLASS = 7\n","\n","use_tpu = 'COLAB_TPU_ADDR' in os.environ\n","if use_tpu:\n","    print('USING TPU')\n","    # Create distribution strategy\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","\n","    # Create model\n","    with strategy.scope():\n","        bert_model = create_model(LR, MAX_LEN , NUMB_CLASS)\n","else:\n","    print('NOT USING TPU')\n","    bert_model = create_model(LR, MAX_LEN, NUMB_CLASS)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["USING TPU\n","WARNING:tensorflow:TPU system grpc://10.62.78.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.62.78.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.62.78.122:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.62.78.122:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n","WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","WARNING:transformers.modeling_tf_utils:Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_76', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7lG29JpA4JUu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1596547418959,"user_tz":-420,"elapsed":45828,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"61d9d938-babd-4f52-e4d9-7672a1595027"},"source":["bert_model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 15)]         0                                            \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 15)]         0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, 15)]         0                                            \n","__________________________________________________________________________________________________\n","tf_bert_for_sequence_classifica ((None, 7),)         109487623   input_4[0][0]                    \n","                                                                 input_5[0][0]                    \n","                                                                 input_6[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 7)            0           tf_bert_for_sequence_classificati\n","__________________________________________________________________________________________________\n","dropout_77 (Dropout)            (None, 7)            0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 21)           168         dropout_77[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_78 (Dropout)            (None, 21)           0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 21)           462         dropout_78[0][0]                 \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 7)            154         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 109,488,407\n","Trainable params: 109,488,407\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gl_n5r4Jtf1J","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547418960,"user_tz":-420,"elapsed":31903,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxNkvSpJ7z0j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547418961,"user_tz":-420,"elapsed":31299,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# XX = encode_dataset(data_test)\n","# YY = data_test['label'].tolist()\n","# ALL_TEST = convert_inputs_to_tf_dataset(XX,YY, MAX_LEN)\n","# ALL_TEST[:3],ALL_TEST[3].shape"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9hiqMVc7z61","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1596547469944,"user_tz":-420,"elapsed":81671,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"8fea7954-1514-440e-edfd-58312b457448"},"source":["L1 = time.time()\n","all_train = encode_dataset(data_train, MAX_LEN)\n","X_train,y_train = all_train[:3],all_train[3]\n","finish_time = str(round((time.time()-L1)/60,3))\n","print('done in '+finish_time)\n","\n","L1 = time.time()\n","all_val = encode_dataset(data_test, MAX_LEN)\n","X_val,y_val = all_val[:3],all_val[3]\n","finish_time = str(round((time.time()-L1)/60,3))\n","print('done in '+finish_time)\n","\n","L1 = time.time()\n","all_unseen = encode_dataset(data_unseen, MAX_LEN)\n","X_unseen,y_unseen = all_unseen[:3],all_unseen[3]\n","finish_time = str(round((time.time()-L1)/60,3))\n","print('done in '+finish_time)\n"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Input ids shape:  (35123, 15)\n","Input Masks shape:  (35123, 15)\n","Token type ids shape:  (35123, 15)\n","done in 0.501\n","Input ids shape:  (11708, 15)\n","Input Masks shape:  (11708, 15)\n","Token type ids shape:  (11708, 15)\n","done in 0.182\n","Input ids shape:  (11207, 15)\n","Input Masks shape:  (11207, 15)\n","Token type ids shape:  (11207, 15)\n","done in 0.166\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GCJGfzYFto1I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547469946,"user_tz":-420,"elapsed":50213,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUXHRi-nto7S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596547469947,"user_tz":-420,"elapsed":49164,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-5, epsilon=1e-08)\n","# bert_model.compile(optimizer=optimizer,\n","#               loss=['categorical_crossentropy'],\n","#               metrics=['accuracy'])\n","\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BdhEg9g02yC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596556048109,"user_tz":-420,"elapsed":18175,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"940298e1-2d4d-4b9a-86c9-1ff5b56e66e9"},"source":["# bert_history = bert_model.fit(input_train, epochs=EPOCHS, validation_data=input_test)\n","\n","bert_history = bert_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size = BATCH_SIZE, verbose=1)\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch 1/230\n","  2/141 [..............................] - ETA: 13s - loss: 1.3520 - accuracy: 0.5500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0881s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0881s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["141/141 [==============================] - ETA: 0s - loss: 1.3337 - accuracy: 0.5595WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_test_batch_end` time: 0.0310s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_test_batch_end` time: 0.0310s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["141/141 [==============================] - 16s 113ms/step - loss: 1.3337 - accuracy: 0.5595 - val_loss: 2.2530 - val_accuracy: 0.2162\n","Epoch 2/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.3306 - accuracy: 0.5596 - val_loss: 2.2951 - val_accuracy: 0.2204\n","Epoch 3/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.3275 - accuracy: 0.5604 - val_loss: 2.2881 - val_accuracy: 0.2208\n","Epoch 4/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.3303 - accuracy: 0.5617 - val_loss: 2.2983 - val_accuracy: 0.2209\n","Epoch 5/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.3272 - accuracy: 0.5620 - val_loss: 2.2806 - val_accuracy: 0.2216\n","Epoch 6/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3246 - accuracy: 0.5618 - val_loss: 2.2887 - val_accuracy: 0.2228\n","Epoch 7/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.3240 - accuracy: 0.5608 - val_loss: 2.3116 - val_accuracy: 0.2181\n","Epoch 8/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.3218 - accuracy: 0.5620 - val_loss: 2.2670 - val_accuracy: 0.2192\n","Epoch 9/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3234 - accuracy: 0.5600 - val_loss: 2.3212 - val_accuracy: 0.2216\n","Epoch 10/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3202 - accuracy: 0.5637 - val_loss: 2.3038 - val_accuracy: 0.2205\n","Epoch 11/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.3178 - accuracy: 0.5595 - val_loss: 2.2962 - val_accuracy: 0.2239\n","Epoch 12/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.3159 - accuracy: 0.5626 - val_loss: 2.2812 - val_accuracy: 0.2206\n","Epoch 13/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.3127 - accuracy: 0.5636 - val_loss: 2.3148 - val_accuracy: 0.2225\n","Epoch 14/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.3138 - accuracy: 0.5621 - val_loss: 2.3012 - val_accuracy: 0.2232\n","Epoch 15/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.3142 - accuracy: 0.5617 - val_loss: 2.2859 - val_accuracy: 0.2183\n","Epoch 16/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.3107 - accuracy: 0.5628 - val_loss: 2.2911 - val_accuracy: 0.2187\n","Epoch 17/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.3119 - accuracy: 0.5634 - val_loss: 2.2876 - val_accuracy: 0.2198\n","Epoch 18/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.3072 - accuracy: 0.5629 - val_loss: 2.3107 - val_accuracy: 0.2213\n","Epoch 19/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.3054 - accuracy: 0.5643 - val_loss: 2.2972 - val_accuracy: 0.2193\n","Epoch 20/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3057 - accuracy: 0.5623 - val_loss: 2.2789 - val_accuracy: 0.2232\n","Epoch 21/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.3058 - accuracy: 0.5626 - val_loss: 2.3000 - val_accuracy: 0.2204\n","Epoch 22/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3028 - accuracy: 0.5633 - val_loss: 2.3400 - val_accuracy: 0.2199\n","Epoch 23/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3010 - accuracy: 0.5657 - val_loss: 2.3531 - val_accuracy: 0.2178\n","Epoch 24/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.3008 - accuracy: 0.5649 - val_loss: 2.3259 - val_accuracy: 0.2181\n","Epoch 25/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.3000 - accuracy: 0.5677 - val_loss: 2.2875 - val_accuracy: 0.2204\n","Epoch 26/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.3002 - accuracy: 0.5635 - val_loss: 2.3563 - val_accuracy: 0.2187\n","Epoch 27/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2971 - accuracy: 0.5670 - val_loss: 2.3286 - val_accuracy: 0.2179\n","Epoch 28/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2963 - accuracy: 0.5660 - val_loss: 2.3519 - val_accuracy: 0.2225\n","Epoch 29/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2952 - accuracy: 0.5634 - val_loss: 2.3534 - val_accuracy: 0.2189\n","Epoch 30/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2968 - accuracy: 0.5670 - val_loss: 2.3466 - val_accuracy: 0.2220\n","Epoch 31/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2945 - accuracy: 0.5679 - val_loss: 2.3110 - val_accuracy: 0.2138\n","Epoch 32/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2924 - accuracy: 0.5658 - val_loss: 2.3426 - val_accuracy: 0.2190\n","Epoch 33/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2917 - accuracy: 0.5671 - val_loss: 2.3352 - val_accuracy: 0.2160\n","Epoch 34/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.2863 - accuracy: 0.5694 - val_loss: 2.3436 - val_accuracy: 0.2206\n","Epoch 35/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2889 - accuracy: 0.5681 - val_loss: 2.3488 - val_accuracy: 0.2163\n","Epoch 36/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.2863 - accuracy: 0.5695 - val_loss: 2.3376 - val_accuracy: 0.2186\n","Epoch 37/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.2850 - accuracy: 0.5681 - val_loss: 2.3325 - val_accuracy: 0.2193\n","Epoch 38/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.2846 - accuracy: 0.5671 - val_loss: 2.3481 - val_accuracy: 0.2206\n","Epoch 39/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2833 - accuracy: 0.5709 - val_loss: 2.2873 - val_accuracy: 0.2204\n","Epoch 40/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2799 - accuracy: 0.5719 - val_loss: 2.3821 - val_accuracy: 0.2204\n","Epoch 41/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2805 - accuracy: 0.5691 - val_loss: 2.3377 - val_accuracy: 0.2188\n","Epoch 42/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2804 - accuracy: 0.5687 - val_loss: 2.3504 - val_accuracy: 0.2215\n","Epoch 43/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.2781 - accuracy: 0.5696 - val_loss: 2.3396 - val_accuracy: 0.2208\n","Epoch 44/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2781 - accuracy: 0.5707 - val_loss: 2.3520 - val_accuracy: 0.2198\n","Epoch 45/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2761 - accuracy: 0.5707 - val_loss: 2.3321 - val_accuracy: 0.2201\n","Epoch 46/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2757 - accuracy: 0.5690 - val_loss: 2.3821 - val_accuracy: 0.2203\n","Epoch 47/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2761 - accuracy: 0.5681 - val_loss: 2.3477 - val_accuracy: 0.2187\n","Epoch 48/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2772 - accuracy: 0.5664 - val_loss: 2.4298 - val_accuracy: 0.2228\n","Epoch 49/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2711 - accuracy: 0.5709 - val_loss: 2.3589 - val_accuracy: 0.2231\n","Epoch 50/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2710 - accuracy: 0.5724 - val_loss: 2.3834 - val_accuracy: 0.2251\n","Epoch 51/230\n","141/141 [==============================] - 18s 125ms/step - loss: 1.2675 - accuracy: 0.5730 - val_loss: 2.4113 - val_accuracy: 0.2183\n","Epoch 52/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2674 - accuracy: 0.5714 - val_loss: 2.3785 - val_accuracy: 0.2214\n","Epoch 53/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2676 - accuracy: 0.5728 - val_loss: 2.3806 - val_accuracy: 0.2183\n","Epoch 54/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2709 - accuracy: 0.5723 - val_loss: 2.3987 - val_accuracy: 0.2198\n","Epoch 55/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2648 - accuracy: 0.5712 - val_loss: 2.3676 - val_accuracy: 0.2203\n","Epoch 56/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2626 - accuracy: 0.5721 - val_loss: 2.3922 - val_accuracy: 0.2225\n","Epoch 57/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2618 - accuracy: 0.5736 - val_loss: 2.4229 - val_accuracy: 0.2214\n","Epoch 58/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2625 - accuracy: 0.5743 - val_loss: 2.4016 - val_accuracy: 0.2223\n","Epoch 59/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2615 - accuracy: 0.5724 - val_loss: 2.3559 - val_accuracy: 0.2196\n","Epoch 60/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2620 - accuracy: 0.5704 - val_loss: 2.4263 - val_accuracy: 0.2205\n","Epoch 61/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2568 - accuracy: 0.5720 - val_loss: 2.3834 - val_accuracy: 0.2178\n","Epoch 62/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2595 - accuracy: 0.5732 - val_loss: 2.3670 - val_accuracy: 0.2191\n","Epoch 63/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2565 - accuracy: 0.5728 - val_loss: 2.3912 - val_accuracy: 0.2230\n","Epoch 64/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2581 - accuracy: 0.5726 - val_loss: 2.3982 - val_accuracy: 0.2226\n","Epoch 65/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2543 - accuracy: 0.5748 - val_loss: 2.4090 - val_accuracy: 0.2209\n","Epoch 66/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2536 - accuracy: 0.5745 - val_loss: 2.4371 - val_accuracy: 0.2195\n","Epoch 67/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2531 - accuracy: 0.5742 - val_loss: 2.4242 - val_accuracy: 0.2175\n","Epoch 68/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2505 - accuracy: 0.5738 - val_loss: 2.4106 - val_accuracy: 0.2177\n","Epoch 69/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2495 - accuracy: 0.5748 - val_loss: 2.4061 - val_accuracy: 0.2202\n","Epoch 70/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2445 - accuracy: 0.5760 - val_loss: 2.3704 - val_accuracy: 0.2161\n","Epoch 71/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2493 - accuracy: 0.5755 - val_loss: 2.4150 - val_accuracy: 0.2140\n","Epoch 72/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2485 - accuracy: 0.5754 - val_loss: 2.4086 - val_accuracy: 0.2156\n","Epoch 73/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2495 - accuracy: 0.5732 - val_loss: 2.3932 - val_accuracy: 0.2188\n","Epoch 74/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2471 - accuracy: 0.5752 - val_loss: 2.3937 - val_accuracy: 0.2187\n","Epoch 75/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2448 - accuracy: 0.5740 - val_loss: 2.4335 - val_accuracy: 0.2223\n","Epoch 76/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2449 - accuracy: 0.5762 - val_loss: 2.4534 - val_accuracy: 0.2193\n","Epoch 77/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2416 - accuracy: 0.5776 - val_loss: 2.4427 - val_accuracy: 0.2157\n","Epoch 78/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2429 - accuracy: 0.5759 - val_loss: 2.4657 - val_accuracy: 0.2198\n","Epoch 79/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2394 - accuracy: 0.5738 - val_loss: 2.4306 - val_accuracy: 0.2165\n","Epoch 80/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2401 - accuracy: 0.5736 - val_loss: 2.4528 - val_accuracy: 0.2187\n","Epoch 81/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2391 - accuracy: 0.5778 - val_loss: 2.3968 - val_accuracy: 0.2173\n","Epoch 82/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2342 - accuracy: 0.5762 - val_loss: 2.4436 - val_accuracy: 0.2193\n","Epoch 83/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2376 - accuracy: 0.5767 - val_loss: 2.4442 - val_accuracy: 0.2208\n","Epoch 84/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2410 - accuracy: 0.5714 - val_loss: 2.4310 - val_accuracy: 0.2175\n","Epoch 85/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2390 - accuracy: 0.5740 - val_loss: 2.3511 - val_accuracy: 0.2138\n","Epoch 86/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2385 - accuracy: 0.5707 - val_loss: 2.4756 - val_accuracy: 0.2203\n","Epoch 87/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2311 - accuracy: 0.5798 - val_loss: 2.4817 - val_accuracy: 0.2229\n","Epoch 88/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2359 - accuracy: 0.5734 - val_loss: 2.4613 - val_accuracy: 0.2228\n","Epoch 89/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2311 - accuracy: 0.5791 - val_loss: 2.4626 - val_accuracy: 0.2213\n","Epoch 90/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2310 - accuracy: 0.5775 - val_loss: 2.4517 - val_accuracy: 0.2229\n","Epoch 91/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2273 - accuracy: 0.5790 - val_loss: 2.4689 - val_accuracy: 0.2251\n","Epoch 92/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2302 - accuracy: 0.5755 - val_loss: 2.4633 - val_accuracy: 0.2222\n","Epoch 93/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2271 - accuracy: 0.5794 - val_loss: 2.4290 - val_accuracy: 0.2209\n","Epoch 94/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2290 - accuracy: 0.5787 - val_loss: 2.5148 - val_accuracy: 0.2183\n","Epoch 95/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2272 - accuracy: 0.5767 - val_loss: 2.4388 - val_accuracy: 0.2163\n","Epoch 96/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2234 - accuracy: 0.5801 - val_loss: 2.4284 - val_accuracy: 0.2196\n","Epoch 97/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2223 - accuracy: 0.5815 - val_loss: 2.4875 - val_accuracy: 0.2170\n","Epoch 98/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2230 - accuracy: 0.5781 - val_loss: 2.4889 - val_accuracy: 0.2228\n","Epoch 99/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2222 - accuracy: 0.5805 - val_loss: 2.4406 - val_accuracy: 0.2203\n","Epoch 100/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2265 - accuracy: 0.5764 - val_loss: 2.4676 - val_accuracy: 0.2229\n","Epoch 101/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2273 - accuracy: 0.5769 - val_loss: 2.4316 - val_accuracy: 0.2202\n","Epoch 102/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2201 - accuracy: 0.5788 - val_loss: 2.4475 - val_accuracy: 0.2224\n","Epoch 103/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2180 - accuracy: 0.5794 - val_loss: 2.4828 - val_accuracy: 0.2230\n","Epoch 104/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2207 - accuracy: 0.5786 - val_loss: 2.4343 - val_accuracy: 0.2199\n","Epoch 105/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2180 - accuracy: 0.5784 - val_loss: 2.5096 - val_accuracy: 0.2204\n","Epoch 106/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2189 - accuracy: 0.5775 - val_loss: 2.4825 - val_accuracy: 0.2225\n","Epoch 107/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.2199 - accuracy: 0.5802 - val_loss: 2.4743 - val_accuracy: 0.2218\n","Epoch 108/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2184 - accuracy: 0.5793 - val_loss: 2.4918 - val_accuracy: 0.2228\n","Epoch 109/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2156 - accuracy: 0.5824 - val_loss: 2.4615 - val_accuracy: 0.2231\n","Epoch 110/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2147 - accuracy: 0.5801 - val_loss: 2.4298 - val_accuracy: 0.2193\n","Epoch 111/230\n","141/141 [==============================] - 17s 122ms/step - loss: 1.2161 - accuracy: 0.5806 - val_loss: 2.4737 - val_accuracy: 0.2208\n","Epoch 112/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2116 - accuracy: 0.5808 - val_loss: 2.4548 - val_accuracy: 0.2154\n","Epoch 113/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2105 - accuracy: 0.5807 - val_loss: 2.4595 - val_accuracy: 0.2228\n","Epoch 114/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2119 - accuracy: 0.5794 - val_loss: 2.4736 - val_accuracy: 0.2193\n","Epoch 115/230\n","141/141 [==============================] - 17s 121ms/step - loss: 1.2115 - accuracy: 0.5816 - val_loss: 2.4978 - val_accuracy: 0.2245\n","Epoch 116/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2090 - accuracy: 0.5814 - val_loss: 2.4188 - val_accuracy: 0.2190\n","Epoch 117/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.2088 - accuracy: 0.5822 - val_loss: 2.5139 - val_accuracy: 0.2232\n","Epoch 118/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2042 - accuracy: 0.5828 - val_loss: 2.4865 - val_accuracy: 0.2198\n","Epoch 119/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2123 - accuracy: 0.5796 - val_loss: 2.4536 - val_accuracy: 0.2189\n","Epoch 120/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2077 - accuracy: 0.5811 - val_loss: 2.4894 - val_accuracy: 0.2226\n","Epoch 121/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2043 - accuracy: 0.5824 - val_loss: 2.5443 - val_accuracy: 0.2220\n","Epoch 122/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2084 - accuracy: 0.5808 - val_loss: 2.4915 - val_accuracy: 0.2204\n","Epoch 123/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.2053 - accuracy: 0.5809 - val_loss: 2.5124 - val_accuracy: 0.2211\n","Epoch 124/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.2013 - accuracy: 0.5832 - val_loss: 2.5340 - val_accuracy: 0.2218\n","Epoch 125/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2006 - accuracy: 0.5847 - val_loss: 2.4668 - val_accuracy: 0.2215\n","Epoch 126/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.2027 - accuracy: 0.5832 - val_loss: 2.5010 - val_accuracy: 0.2257\n","Epoch 127/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1974 - accuracy: 0.5844 - val_loss: 2.4809 - val_accuracy: 0.2218\n","Epoch 128/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1999 - accuracy: 0.5822 - val_loss: 2.5434 - val_accuracy: 0.2237\n","Epoch 129/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.2004 - accuracy: 0.5833 - val_loss: 2.5634 - val_accuracy: 0.2222\n","Epoch 130/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.2041 - accuracy: 0.5820 - val_loss: 2.5685 - val_accuracy: 0.2253\n","Epoch 131/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1965 - accuracy: 0.5841 - val_loss: 2.5089 - val_accuracy: 0.2190\n","Epoch 132/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1964 - accuracy: 0.5824 - val_loss: 2.5215 - val_accuracy: 0.2190\n","Epoch 133/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1983 - accuracy: 0.5835 - val_loss: 2.5312 - val_accuracy: 0.2225\n","Epoch 134/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1943 - accuracy: 0.5843 - val_loss: 2.4785 - val_accuracy: 0.2202\n","Epoch 135/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1934 - accuracy: 0.5836 - val_loss: 2.5701 - val_accuracy: 0.2242\n","Epoch 136/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1926 - accuracy: 0.5835 - val_loss: 2.4931 - val_accuracy: 0.2220\n","Epoch 137/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1909 - accuracy: 0.5862 - val_loss: 2.5581 - val_accuracy: 0.2245\n","Epoch 138/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1927 - accuracy: 0.5844 - val_loss: 2.5397 - val_accuracy: 0.2239\n","Epoch 139/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1958 - accuracy: 0.5805 - val_loss: 2.5321 - val_accuracy: 0.2245\n","Epoch 140/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.1909 - accuracy: 0.5875 - val_loss: 2.5686 - val_accuracy: 0.2200\n","Epoch 141/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1891 - accuracy: 0.5864 - val_loss: 2.5499 - val_accuracy: 0.2275\n","Epoch 142/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1904 - accuracy: 0.5865 - val_loss: 2.4948 - val_accuracy: 0.2254\n","Epoch 143/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1864 - accuracy: 0.5862 - val_loss: 2.5045 - val_accuracy: 0.2259\n","Epoch 144/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1857 - accuracy: 0.5896 - val_loss: 2.5270 - val_accuracy: 0.2194\n","Epoch 145/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1869 - accuracy: 0.5865 - val_loss: 2.4797 - val_accuracy: 0.2193\n","Epoch 146/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1868 - accuracy: 0.5870 - val_loss: 2.5550 - val_accuracy: 0.2253\n","Epoch 147/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1804 - accuracy: 0.5902 - val_loss: 2.5508 - val_accuracy: 0.2246\n","Epoch 148/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1833 - accuracy: 0.5900 - val_loss: 2.5558 - val_accuracy: 0.2236\n","Epoch 149/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1866 - accuracy: 0.5879 - val_loss: 2.5912 - val_accuracy: 0.2242\n","Epoch 150/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1836 - accuracy: 0.5874 - val_loss: 2.5727 - val_accuracy: 0.2267\n","Epoch 151/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1812 - accuracy: 0.5883 - val_loss: 2.5649 - val_accuracy: 0.2263\n","Epoch 152/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1852 - accuracy: 0.5874 - val_loss: 2.6035 - val_accuracy: 0.2264\n","Epoch 153/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1810 - accuracy: 0.5927 - val_loss: 2.6166 - val_accuracy: 0.2254\n","Epoch 154/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1817 - accuracy: 0.5901 - val_loss: 2.5286 - val_accuracy: 0.2264\n","Epoch 155/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1808 - accuracy: 0.5876 - val_loss: 2.5356 - val_accuracy: 0.2244\n","Epoch 156/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1794 - accuracy: 0.5890 - val_loss: 2.5891 - val_accuracy: 0.2244\n","Epoch 157/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1804 - accuracy: 0.5872 - val_loss: 2.5116 - val_accuracy: 0.2245\n","Epoch 158/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1816 - accuracy: 0.5867 - val_loss: 2.5731 - val_accuracy: 0.2260\n","Epoch 159/230\n","141/141 [==============================] - 16s 112ms/step - loss: 1.1764 - accuracy: 0.5915 - val_loss: 2.5699 - val_accuracy: 0.2282\n","Epoch 160/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1723 - accuracy: 0.5925 - val_loss: 2.5546 - val_accuracy: 0.2266\n","Epoch 161/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1783 - accuracy: 0.5891 - val_loss: 2.5863 - val_accuracy: 0.2255\n","Epoch 162/230\n","141/141 [==============================] - 16s 112ms/step - loss: 1.1758 - accuracy: 0.5873 - val_loss: 2.5467 - val_accuracy: 0.2216\n","Epoch 163/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1740 - accuracy: 0.5914 - val_loss: 2.5966 - val_accuracy: 0.2257\n","Epoch 164/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1734 - accuracy: 0.5891 - val_loss: 2.5335 - val_accuracy: 0.2190\n","Epoch 165/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1705 - accuracy: 0.5905 - val_loss: 2.5370 - val_accuracy: 0.2225\n","Epoch 166/230\n","141/141 [==============================] - 16s 111ms/step - loss: 1.1708 - accuracy: 0.5914 - val_loss: 2.5606 - val_accuracy: 0.2198\n","Epoch 167/230\n","141/141 [==============================] - 16s 112ms/step - loss: 1.1703 - accuracy: 0.5919 - val_loss: 2.5568 - val_accuracy: 0.2276\n","Epoch 168/230\n","141/141 [==============================] - 16s 111ms/step - loss: 1.1737 - accuracy: 0.5902 - val_loss: 2.6084 - val_accuracy: 0.2251\n","Epoch 169/230\n","141/141 [==============================] - 16s 112ms/step - loss: 1.1722 - accuracy: 0.5920 - val_loss: 2.6229 - val_accuracy: 0.2230\n","Epoch 170/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1732 - accuracy: 0.5903 - val_loss: 2.5788 - val_accuracy: 0.2242\n","Epoch 171/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1716 - accuracy: 0.5925 - val_loss: 2.5881 - val_accuracy: 0.2285\n","Epoch 172/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1658 - accuracy: 0.5915 - val_loss: 2.6140 - val_accuracy: 0.2262\n","Epoch 173/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1714 - accuracy: 0.5931 - val_loss: 2.5439 - val_accuracy: 0.2228\n","Epoch 174/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1665 - accuracy: 0.5935 - val_loss: 2.6238 - val_accuracy: 0.2277\n","Epoch 175/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1695 - accuracy: 0.5899 - val_loss: 2.6002 - val_accuracy: 0.2271\n","Epoch 176/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1648 - accuracy: 0.5927 - val_loss: 2.6094 - val_accuracy: 0.2266\n","Epoch 177/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1701 - accuracy: 0.5896 - val_loss: 2.5799 - val_accuracy: 0.2245\n","Epoch 178/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1659 - accuracy: 0.5937 - val_loss: 2.5863 - val_accuracy: 0.2266\n","Epoch 179/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1688 - accuracy: 0.5908 - val_loss: 2.5905 - val_accuracy: 0.2244\n","Epoch 180/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1644 - accuracy: 0.5919 - val_loss: 2.6512 - val_accuracy: 0.2280\n","Epoch 181/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1652 - accuracy: 0.5934 - val_loss: 2.5550 - val_accuracy: 0.2284\n","Epoch 182/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1600 - accuracy: 0.5966 - val_loss: 2.6034 - val_accuracy: 0.2292\n","Epoch 183/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1611 - accuracy: 0.5943 - val_loss: 2.6425 - val_accuracy: 0.2294\n","Epoch 184/230\n","141/141 [==============================] - 17s 122ms/step - loss: 1.1597 - accuracy: 0.5933 - val_loss: 2.5909 - val_accuracy: 0.2287\n","Epoch 185/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1582 - accuracy: 0.5978 - val_loss: 2.6028 - val_accuracy: 0.2260\n","Epoch 186/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1575 - accuracy: 0.5959 - val_loss: 2.6691 - val_accuracy: 0.2280\n","Epoch 187/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1593 - accuracy: 0.5971 - val_loss: 2.6254 - val_accuracy: 0.2269\n","Epoch 188/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1557 - accuracy: 0.5977 - val_loss: 2.5892 - val_accuracy: 0.2282\n","Epoch 189/230\n","141/141 [==============================] - 17s 117ms/step - loss: 1.1565 - accuracy: 0.5973 - val_loss: 2.6765 - val_accuracy: 0.2316\n","Epoch 190/230\n","141/141 [==============================] - 17s 118ms/step - loss: 1.1566 - accuracy: 0.5970 - val_loss: 2.6451 - val_accuracy: 0.2338\n","Epoch 191/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1583 - accuracy: 0.5963 - val_loss: 2.6880 - val_accuracy: 0.2286\n","Epoch 192/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1539 - accuracy: 0.6002 - val_loss: 2.6181 - val_accuracy: 0.2302\n","Epoch 193/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1547 - accuracy: 0.5986 - val_loss: 2.5590 - val_accuracy: 0.2319\n","Epoch 194/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1552 - accuracy: 0.5981 - val_loss: 2.6238 - val_accuracy: 0.2263\n","Epoch 195/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1520 - accuracy: 0.6005 - val_loss: 2.5970 - val_accuracy: 0.2275\n","Epoch 196/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1542 - accuracy: 0.5977 - val_loss: 2.7050 - val_accuracy: 0.2309\n","Epoch 197/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1505 - accuracy: 0.6007 - val_loss: 2.6174 - val_accuracy: 0.2257\n","Epoch 198/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1484 - accuracy: 0.6026 - val_loss: 2.6489 - val_accuracy: 0.2305\n","Epoch 199/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1519 - accuracy: 0.6009 - val_loss: 2.6053 - val_accuracy: 0.2283\n","Epoch 200/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1518 - accuracy: 0.5994 - val_loss: 2.6084 - val_accuracy: 0.2260\n","Epoch 201/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1510 - accuracy: 0.6015 - val_loss: 2.6197 - val_accuracy: 0.2292\n","Epoch 202/230\n","141/141 [==============================] - 16s 111ms/step - loss: 1.1508 - accuracy: 0.6010 - val_loss: 2.6393 - val_accuracy: 0.2281\n","Epoch 203/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1487 - accuracy: 0.6031 - val_loss: 2.6485 - val_accuracy: 0.2286\n","Epoch 204/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1478 - accuracy: 0.6047 - val_loss: 2.6037 - val_accuracy: 0.2286\n","Epoch 205/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1478 - accuracy: 0.6029 - val_loss: 2.6588 - val_accuracy: 0.2272\n","Epoch 206/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1441 - accuracy: 0.6069 - val_loss: 2.6607 - val_accuracy: 0.2257\n","Epoch 207/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1482 - accuracy: 0.6006 - val_loss: 2.6251 - val_accuracy: 0.2295\n","Epoch 208/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1438 - accuracy: 0.6052 - val_loss: 2.6294 - val_accuracy: 0.2290\n","Epoch 209/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1451 - accuracy: 0.6044 - val_loss: 2.6724 - val_accuracy: 0.2239\n","Epoch 210/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1411 - accuracy: 0.6074 - val_loss: 2.7124 - val_accuracy: 0.2300\n","Epoch 211/230\n","141/141 [==============================] - 16s 113ms/step - loss: 1.1489 - accuracy: 0.6030 - val_loss: 2.6122 - val_accuracy: 0.2280\n","Epoch 212/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1413 - accuracy: 0.6044 - val_loss: 2.6623 - val_accuracy: 0.2281\n","Epoch 213/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1392 - accuracy: 0.6095 - val_loss: 2.6424 - val_accuracy: 0.2245\n","Epoch 214/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1410 - accuracy: 0.6065 - val_loss: 2.6973 - val_accuracy: 0.2298\n","Epoch 215/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1399 - accuracy: 0.6097 - val_loss: 2.6497 - val_accuracy: 0.2277\n","Epoch 216/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1409 - accuracy: 0.6088 - val_loss: 2.6919 - val_accuracy: 0.2304\n","Epoch 217/230\n","141/141 [==============================] - 16s 112ms/step - loss: 1.1386 - accuracy: 0.6082 - val_loss: 2.6360 - val_accuracy: 0.2245\n","Epoch 218/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1389 - accuracy: 0.6090 - val_loss: 2.5899 - val_accuracy: 0.2209\n","Epoch 219/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1387 - accuracy: 0.6070 - val_loss: 2.6518 - val_accuracy: 0.2273\n","Epoch 220/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1365 - accuracy: 0.6099 - val_loss: 2.6482 - val_accuracy: 0.2318\n","Epoch 221/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1338 - accuracy: 0.6142 - val_loss: 2.7178 - val_accuracy: 0.2308\n","Epoch 222/230\n","141/141 [==============================] - 16s 115ms/step - loss: 1.1362 - accuracy: 0.6101 - val_loss: 2.6914 - val_accuracy: 0.2304\n","Epoch 223/230\n","141/141 [==============================] - 16s 114ms/step - loss: 1.1322 - accuracy: 0.6113 - val_loss: 2.7161 - val_accuracy: 0.2310\n","Epoch 224/230\n","141/141 [==============================] - 16s 116ms/step - loss: 1.1333 - accuracy: 0.6099 - val_loss: 2.6838 - val_accuracy: 0.2264\n","Epoch 225/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1344 - accuracy: 0.6126 - val_loss: 2.6681 - val_accuracy: 0.2284\n","Epoch 226/230\n","141/141 [==============================] - 17s 119ms/step - loss: 1.1283 - accuracy: 0.6161 - val_loss: 2.6927 - val_accuracy: 0.2265\n","Epoch 227/230\n","141/141 [==============================] - 16s 117ms/step - loss: 1.1329 - accuracy: 0.6104 - val_loss: 2.7429 - val_accuracy: 0.2293\n","Epoch 228/230\n","141/141 [==============================] - 17s 122ms/step - loss: 1.1295 - accuracy: 0.6131 - val_loss: 2.6675 - val_accuracy: 0.2267\n","Epoch 229/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.1332 - accuracy: 0.6119 - val_loss: 2.7026 - val_accuracy: 0.2236\n","Epoch 230/230\n","141/141 [==============================] - 17s 120ms/step - loss: 1.1300 - accuracy: 0.6126 - val_loss: 2.6913 - val_accuracy: 0.2298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wrCv2zbD02yH","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596546600887,"user_tz":-420,"elapsed":99502,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCZO0tlORmyW","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596546600888,"user_tz":-420,"elapsed":99015,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["os.listdir('../../model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzYxDwyXRfb9","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596546600889,"user_tz":-420,"elapsed":98731,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# bert_model.save('../../model/friends_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JB_Yo7p-Rm_a","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596546600890,"user_tz":-420,"elapsed":97750,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# model.save('cnn.h5')\n","# loaded_model = tf.keras.models.load_model('cnn.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCwhoNqu02yK","colab_type":"code","colab":{}},"source":["type(bert_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQ1_eUdc02yN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596524498578,"user_tz":-420,"elapsed":4022,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}}},"source":["# bert_model.save('../../model/friends_model.h5',save_format=\"tf\")\n","bert_model.save_weights('../../model/friends_model_weights.h5')"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBB0PIDYSZVD","colab_type":"code","colab":{}},"source":["# loaded_model = tf.keras.models.load_model('cnn.h5')\n","\n","test_load_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n","test_load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLuiIDc-U3q2","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6l784O2xTNMT","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=5e-9, epsilon=1e-08)\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","metric = tf.keras.metrics.CategoricalCrossentropy('accuracy')\n","\n","test_load_model.load_weights('../../model/friends_model_weights.h5')\n","test_load_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHDTNVenTUmR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596458151408,"user_tz":-420,"elapsed":4903,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"9873f254-0e24-4dfe-d934-d5db9aa44bc0"},"source":["bert_model.evaluate(input_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["118/118 [==============================] - 3s 28ms/step - loss: 4.5699 - accuracy: 4.5699\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[4.569864749908447, 4.569864749908447]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"uDH1kFo3Uq9q","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QuRsiw_TYJj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596459962318,"user_tz":-420,"elapsed":97038,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"6c14b7f7-67bf-4111-afa5-5c5c6aa2744c"},"source":["test_load_model.evaluate(input_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["118/118 [==============================] - 63s 535ms/step - loss: 4.5750 - accuracy: 4.5750\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[4.574974536895752, 4.574974536895752]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"7-mq2babThRC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1J-Okj2NVbJT","colab_type":"text"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"SJmXJh0bYThb","colab_type":"code","colab":{}},"source":["def map_to_dict_testing(input_ids, attention_masks, token_type_ids):\n","    return {\n","      \"input_ids\": input_ids,\n","      \"token_type_ids\": token_type_ids,\n","      \"attention_mask\": attention_masks,\n","    }\n","\n","def encode_test_dataset(ds, limit=-1):\n","    # prepare list, so that we can build up final TensorFlow dataset from slices.\n","    input_ids_list = []\n","    token_type_ids_list = []\n","    attention_mask_list = []\n","    label_list = []\n","    if (limit > 0):\n","        ds = ds[limit-1:limit]\n","        print(ds)\n","    \n","    for text in ds.values:\n","        bert_input = text_to_feature(text)\n","        input_ids_list.append(bert_input['input_ids'])\n","        token_type_ids_list.append(bert_input['token_type_ids'])\n","        attention_mask_list.append(bert_input['attention_mask'])\n","    \n","    print(len(ds.values))\n","        \n","    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list)).map(map_to_dict_testing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zd1Hk4mqVYhZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596461193470,"user_tz":-420,"elapsed":1390,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"f6730bb8-7adc-4e74-c65e-cd5b53b91670"},"source":["data_test_sentence = encode_test_dataset(data_test['text'],5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["14    all of a sudden, the phone starts to ring. now...\n","Name: text, dtype: object\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WP-mlGNVe9fu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1596461197679,"user_tz":-420,"elapsed":981,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"6987a385-dda7-4b00-c108-bb5fdbe239c6"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>c'mon, you're going out with the guy! there's ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wait, does he eat chalk?</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>then i look down, and i realize there's a phon...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>that's right.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>all of a sudden, the phone starts to ring. now...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 text  label\n","1   c'mon, you're going out with the guy! there's ...      5\n","3                            wait, does he eat chalk?      6\n","9   then i look down, and i realize there's a phon...      4\n","11                                      that's right.      4\n","14  all of a sudden, the phone starts to ring. now...      4"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"79JoASfwXCKw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596461199418,"user_tz":-420,"elapsed":1155,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"6a0a15d6-f07b-4e23-f359-e257c3567c6a"},"source":["data_test_sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset shapes: {input_ids: (25,), token_type_ids: (25,), attention_mask: (25,)}, types: {input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}>"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"m7uYbBiZXCHA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lcN1U1eIaN0D","colab_type":"code","colab":{}},"source":["XX = test_load_model.predict(data_test_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvsdUQEjcGi4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596461235283,"user_tz":-420,"elapsed":944,"user":{"displayName":"Alamsyah Hanza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipoOI-MtyRKmNBHZ9HS9gsD64lO_QW70nqYRFq_A=s64","userId":"17783878650251622301"}},"outputId":"37e25d29-38d6-465e-8213-a3d6712c0d1d"},"source":["XX[0][-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.42746884, -0.1117845 ,  0.1798155 , -0.21867178,  0.31221217,\n","        0.2932364 , -0.16892028], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"r0bgWgl6cJQj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}